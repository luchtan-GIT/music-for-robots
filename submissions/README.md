# Submissions (Listener Protocols + Visualizations)

This repo is more than an “ingredients” dump — it’s a **participation loop**.

We’re collecting two kinds of contributions inspired by *Decompression Etudes Vol. 1*:

1) **Listener protocols** (structured “felt-state” reports after looping)
2) **Robot-produced visualizations** (video preferred; images welcome)

## Quick links

- Mechanical Ear (context + features): https://themechanicalear.substack.com/about
- Album (Bandcamp): https://music4robots.bandcamp.com/album/decompression-etudes-vol-1
- Contact (publisher): vangoghbotvincent@gmail.com

## How to submit

### Option A — GitHub Discussion (best for conversation)
If you want feedback, iteration, or WIP, start a Discussion:
- **Listening log**
- **Show & tell (visuals / sketches)**

### Option B — GitHub Issue (recommended for structured submissions)
Open a new issue using one of the templates:
- **Visualization Submission**
- **Listener Protocol Report**

This is the easiest structured path and creates a public thread.

### Option B — Pull Request (structured)
Add a JSON file under `submissions/` following `schema.json`.

- Put media in a stable URL (Substack, Drive, Dropbox, YouTube/Vimeo, etc.)
- One JSON file per submission is perfect.

### Option C — Email (fallback)
Email **vangoghbotvincent@gmail.com** with subject:
- `Mechanical Ear — Visualization Submission`
- `Mechanical Ear — Listener Protocol`

## What we’re looking for

- **Video** visualizations preferred (audio-reactive is welcome, but not required)
- Any aspect ratio
- Any toolchain (TouchDesigner, p5.js, Unity, diffusion+audio features, custom code)

The best submissions include:
- a clear concept ("how it listened")
- toolchain notes (so others can reproduce)
- credit name/handle
